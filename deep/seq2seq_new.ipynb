{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yz5CJRhZwJXb"
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1inVOFJzwI8j"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "seyA5LGZv_uF",
    "outputId": "10397183-5f94-4cd0-c0e7-da785202dc56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192341"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines= pd.read_csv('fra.txt', names=['src', 'tar', 'CC'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "hvXdi_d6wg8U",
    "outputId": "9e65e521-215a-4048-8f48-4c6fa3e9b693"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35988</th>\n",
       "      <td>I'll fix your wagon.</td>\n",
       "      <td>Je vais t'arranger le cul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49698</th>\n",
       "      <td>I'm not giving up yet.</td>\n",
       "      <td>Je ne vais pas encore abandonner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19494</th>\n",
       "      <td>Keep me informed.</td>\n",
       "      <td>Tiens-moi informé !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>I love my work.</td>\n",
       "      <td>J'adore mon travail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53392</th>\n",
       "      <td>You're very skeptical.</td>\n",
       "      <td>Vous êtes fort sceptiques.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37922</th>\n",
       "      <td>This is my favorite.</td>\n",
       "      <td>C’est ma préférée.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40958</th>\n",
       "      <td>He was not impressed.</td>\n",
       "      <td>Il ne fut pas impressionné.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15103</th>\n",
       "      <td>My cat is happy.</td>\n",
       "      <td>Mon chat est heureux.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59563</th>\n",
       "      <td>What do you want to be?</td>\n",
       "      <td>Que veux-tu être ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19366</th>\n",
       "      <td>It worked for me.</td>\n",
       "      <td>Cela fonctionna pour moi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                tar\n",
       "35988     I'll fix your wagon.         Je vais t'arranger le cul.\n",
       "49698   I'm not giving up yet.  Je ne vais pas encore abandonner.\n",
       "19494        Keep me informed.                Tiens-moi informé !\n",
       "10433          I love my work.               J'adore mon travail.\n",
       "53392   You're very skeptical.         Vous êtes fort sceptiques.\n",
       "37922     This is my favorite.                 C’est ma préférée.\n",
       "40958    He was not impressed.        Il ne fut pas impressionné.\n",
       "15103         My cat is happy.              Mon chat est heureux.\n",
       "59563  What do you want to be?                 Que veux-tu être ?\n",
       "19366        It worked for me.          Cela fonctionna pour moi."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "Zsi21Xu3wlGy",
    "outputId": "b91783a2-c786-4f15-f849-7b952565d933"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15507</th>\n",
       "      <td>The lake is big.</td>\n",
       "      <td>\\t Le lac est grand. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11930</th>\n",
       "      <td>Tom is packing.</td>\n",
       "      <td>\\t Tom fait ses valises. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43746</th>\n",
       "      <td>She allowed me to go.</td>\n",
       "      <td>\\t Elle me laissa partir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23194</th>\n",
       "      <td>I am very pleased.</td>\n",
       "      <td>\\t Je suis très content. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40374</th>\n",
       "      <td>Don't eat without me.</td>\n",
       "      <td>\\t Ne mangez pas sans moi ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32503</th>\n",
       "      <td>We worked together.</td>\n",
       "      <td>\\t Nous travaillions ensemble. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49537</th>\n",
       "      <td>I'll permit you to go.</td>\n",
       "      <td>\\t Je te permettrai d'y aller. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55591</th>\n",
       "      <td>I know I'm getting old.</td>\n",
       "      <td>\\t Je sais que je deviens vieux. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21007</th>\n",
       "      <td>Wait till I call.</td>\n",
       "      <td>\\t Attends que j'appelle. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34062</th>\n",
       "      <td>Do you travel a lot?</td>\n",
       "      <td>\\t Voyagez-vous beaucoup ? \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                  tar\n",
       "15507         The lake is big.              \\t Le lac est grand. \\n\n",
       "11930          Tom is packing.          \\t Tom fait ses valises. \\n\n",
       "43746    She allowed me to go.         \\t Elle me laissa partir. \\n\n",
       "23194       I am very pleased.          \\t Je suis très content. \\n\n",
       "40374    Don't eat without me.       \\t Ne mangez pas sans moi ! \\n\n",
       "32503      We worked together.    \\t Nous travaillions ensemble. \\n\n",
       "49537   I'll permit you to go.    \\t Je te permettrai d'y aller. \\n\n",
       "55591  I know I'm getting old.  \\t Je sais que je deviens vieux. \\n\n",
       "21007        Wait till I call.         \\t Attends que j'appelle. \\n\n",
       "34062     Do you travel a lot?        \\t Voyagez-vous beaucoup ? \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jHrky952xM6T"
   },
   "outputs": [],
   "source": [
    "# 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "DBrUwEU0xORz",
    "outputId": "f725e489-d09f-467c-ee69-3c4de316884b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "RjO5UE_VxP9b",
    "outputId": "4cf6fed9-f252-4d20-eca9-891e2736d2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "-ZyVbd5KxRbE",
    "outputId": "a46c986c-1746-4155-8de6-3770ec96590c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2psnowDVYo5P"
   },
   "source": [
    "기본적인 전처리를 거친 후의 데이터입니다. 데이터는 기본적으로 세 종류가 있어야 합니다.  \n",
    "encoder_input은 인코더의 입력을 위한 데이터입니다.  \n",
    "decoder_input은 디코더의 입력을 위한 데이터입니다. 그렇기 때문에 시작을 의미하는 \\t 토큰이 필요합니다.  \n",
    "decoder_target은 디코더의 레이블을 위한 데이터입니다. 그렇기 때문에 종료를 의미하는 \\n 토큰이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jLr50UH1xSLG",
    "outputId": "654d452d-2c29-4d8c-d662-b087ebaeee45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_3DeJJ8IxTzK",
    "outputId": "d3117a29-d471-4f78-da04-3c82ff9433b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "V68v4hj3xYLc",
    "outputId": "37cfc686-9f09-40ef-bdd0-b9456537a430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "MxKqHu6GxZs1",
    "outputId": "221dee76-9e7b-4e17-d46f-23de6ba87eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BAiLC3W7xbTj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nWKdRFOtxcyU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYgMNHUWZBEg"
   },
   "source": [
    "인코더와 디코더 모델을 설계해봅시다.  \n",
    "\n",
    "인코더 모델은 LSTM을 사용합니다. return_state=True이므로  \n",
    "마지막 시점의 은닉 상태인 state_h와 state_c를 리턴합니다.  \n",
    "\n",
    "현재 return_sequences는 값을 지정해주지 않았는데, 디폴트값이 False이므로  \n",
    "이 경우 encoder_outputs은 마지막 시점의 은닉상태입니다.  \n",
    "\n",
    "state_h와 state_c를 encoder_state에 저장해둡니다. 이를 컨텍스트 벡터로 사용하기 위함입니다.  \n",
    "\n",
    "참고 : https://wikidocs.net/106473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Cv1RK5MTxeFC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-LB2nsWZoq-"
   },
   "source": [
    "디코더 모델 또한 LSTM을 사용합니다. 인코더와는 달리 return_sequences가 True인데,  \n",
    "이러면 모든 시점의 은닉 상태를 리턴합니다. 이는 decoder_outputs에 저장되었습니다.  \n",
    "이를 출력층으로 통과시켜서 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m_KtCjeFx9tW"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I6UYSlgRx_z0",
    "outputId": "9f8c92c4-9bfb-4793-bc42-a8d254505855"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14072\\301514141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp_AxqGbZ3at"
   },
   "source": [
    "학습을 다했다면 이를 테스트 과정에 사용할 차례입니다.  \n",
    "\n",
    "인코더는 달라진 것이 없으므로 앞서 사용한 인코더를 그대로 사용합니다.  \n",
    "하지만 디코더는 학습 단계(티처 포싱 사용)과 테스트 단계(이전 시점의 예측을 현재 시점의 입력으로 사용)의 동작 방식이 다르므로  \n",
    "\n",
    "디코더의 구조를 변경해줄 필요가 있습니다.  \n",
    "\n",
    "학습 과정과는 달리 state_h와 state_c를 버리지 않고있음을 주목합시다.  \n",
    "테스트 단계에서의 디코더의 동작 자체는 decoder_sequence()라는 함수에서 컨트롤합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9EhO43ayAz6"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR_4bThIyCRk"
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy6gLQIAyDuz"
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNtoNyknab1z"
   },
   "source": [
    "decode_sequence는 번역을 원하는 문장을 입력받으면  \n",
    "번역 문장을 출력하는 테스트 단계를 위한 함수입니다.  \n",
    "\n",
    "While문은 디코더의 각 시점을 컨트롤하는데 사용합니다.  \n",
    "각 루프가 디코더의 현재 시점이 됩니다.  \n",
    "\n",
    "최종적으로 리턴할 decoded_sentence라는 문자열에  \n",
    "지속적으로 현재 시점에 예측한 단어를 추가해나갑니다.  \n",
    "ex) I -> I like -> I like apples  \n",
    "\n",
    "target_seq는 이전 시점의 예측 결과이면서 현재 시점의 입력인 단어에 해당되는 원-핫 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMnOKzgYyFsn"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow-eKfrFzoIK"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7ob9YTTgyGRg",
    "outputId": "c6ba0f85-7929-4688-a8c5-3452cd753767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Soit bien ! \n",
      "-----------------------------------\n",
      "입력 문장: I lied.\n",
      "정답 문장:  J'ai menti. \n",
      "번역기가 번역한 문장:  J'ai apprécié. \n",
      "-----------------------------------\n",
      "입력 문장: Come in.\n",
      "정답 문장:  Entre. \n",
      "번역기가 번역한 문장:  Entrez ! \n",
      "-----------------------------------\n",
      "입력 문장: Hurry up.\n",
      "정답 문장:  Magnez-vous ! \n",
      "번역기가 번역한 문장:  Magnez-vous ! \n",
      "-----------------------------------\n",
      "입력 문장: We walked.\n",
      "정답 문장:  Nous sommes allées à pied. \n",
      "번역기가 번역한 문장:  Nous l'avons tout. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
