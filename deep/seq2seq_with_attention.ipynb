{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d148493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eef57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True\n",
    "\n",
    ")\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+'./spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cda3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Go.</th>\n",
       "      <th>Ve.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118958</th>\n",
       "      <td>There are four main causes of alcohol-related ...</td>\n",
       "      <td>Hay cuatro causas principales de muertes relac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118959</th>\n",
       "      <td>There are mothers and fathers who will lie awa...</td>\n",
       "      <td>Hay madres y padres que se quedan despiertos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118960</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Una huella de carbono es la cantidad de contam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118961</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Como suele haber varias páginas web sobre cual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118962</th>\n",
       "      <td>If you want to sound like a native speaker, yo...</td>\n",
       "      <td>Si quieres sonar como un hablante nativo, debe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118963 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Go.  \\\n",
       "0                                                     Go.   \n",
       "1                                                     Go.   \n",
       "2                                                     Go.   \n",
       "3                                                     Hi.   \n",
       "4                                                    Run!   \n",
       "...                                                   ...   \n",
       "118958  There are four main causes of alcohol-related ...   \n",
       "118959  There are mothers and fathers who will lie awa...   \n",
       "118960  A carbon footprint is the amount of carbon dio...   \n",
       "118961  Since there are usually multiple websites on a...   \n",
       "118962  If you want to sound like a native speaker, yo...   \n",
       "\n",
       "                                                      Ve.  \n",
       "0                                                   Vete.  \n",
       "1                                                   Vaya.  \n",
       "2                                                 Váyase.  \n",
       "3                                                   Hola.  \n",
       "4                                                 ¡Corre!  \n",
       "...                                                   ...  \n",
       "118958  Hay cuatro causas principales de muertes relac...  \n",
       "118959  Hay madres y padres que se quedan despiertos d...  \n",
       "118960  Una huella de carbono es la cantidad de contam...  \n",
       "118961  Como suele haber varias páginas web sobre cual...  \n",
       "118962  Si quieres sonar como un hablante nativo, debe...  \n",
       "\n",
       "[118963 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table('./spa-eng/spa-eng/spa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mec = Mecab(dicpath='C:/mecab/mecab-ko-dic/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278caad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  w = unicode_to_ascii(w.lower().strip())    # 아스키 바꾸는\n",
    "\n",
    "  # 단어와 특수 문자 사이에 공백 넣기\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)  # 대괄호 삭제\n",
    "\n",
    "  # 영어와 일부 특수문자(a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외하고는 전부 공백으로 변환\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()   # 공백 없애기\n",
    "\n",
    "  # 문장의 시작과 끝에 <start> 토큰화 <end> 토큰 추가\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46eb4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23317368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18a287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')  # 읽고, 공백없애고, 줄바꿈으로 쪼개기\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]   # n개의 샘플을 뽑아서 탭으로 쪼개서 토큰을 리스에 담음\n",
    "  return zip(*word_pairs)  # zip으로 묶어줌 => 영어와 스페인어가 매칭되서 묶여짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c169e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "# 지금까지 선언한 전처리 함수들을 실제 데이터셋에 적용한다면?\n",
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa4b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 / 정수 인코딩 / 패딩을 하는 함수\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)   # 문장 학습\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)   # 토큰의 인덱스를 부여\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')     # 길이 맞춤\n",
    "\n",
    "  return tensor, lang_tokenizer   # 토큰과 토큰나이저 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3d3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력된 데이터셋에 대해서 토큰화 / 정수 인코딩 / 패딩을 수행\n",
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)   # 두개 문장 리턴\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)   # 토큰단위로 짜라서 인덱스 값으로 맞추고 패딩이 됨\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02cc8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 수는 3만개로 제한하며  => 5000개\n",
    "# 실제로 토큰화, 정수 인코딩, 패딩을 수행\n",
    "num_examples = 5000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# 최대 길이 계산\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5536df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f392a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1709d746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6fe826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7c5adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 4000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "# 8:2 비율로 분할\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 샘플 개수\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81131c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   17,   81, 2135,    3,    2,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3c7083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   5,  84, 143,   3,   2,   0,   0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7620dfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  73, 873,   3,   2,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feee7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bb99c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> se\n",
      "81 ----> puede\n",
      "2135 ----> romper\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> it\n",
      "84 ----> may\n",
      "143 ----> break\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ea544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9837cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 정의\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256   # 차원\n",
    "units = 1024    # 벡터사이즈\n",
    "\n",
    "# 단어 집합의 크기 정의\n",
    "vocab_inp_size = len(inp_lang.word_index)+1        \n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "# .from_tensor_slices : 데이터를 배치단위로 가져올수 있는 클래스\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd7e4ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 12]), TensorShape([64, 8]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 배치에 대해서 크기 출력\n",
    "example_input_batch, example_target_batch = next(iter(dataset))   # next : next할때마다 배치단위를 가져와서 인풋이랑 타겟을 각각 가져와서 담음\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ee04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4c3c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 구현\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    # 선언부\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units   # lstm 사이즈\n",
    "\n",
    "    # 임베딩 층\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    # GRU\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True, # 인코더의 모든 히든스테이트를 사용.\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')   # 초기값 설정\n",
    "\n",
    "  # 함수형 API와 유사하게 실제 동작은 이곳에서 정의\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)   # 아웃풋과 스테이트 값 출력 됨\n",
    "    return output, state\n",
    "\n",
    "  # 초기 은닉 상태는 제로 벡터로 사용\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a779a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 구현\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)   # 클래스는 객체를 만들어주어야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61c328fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 12, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 제로 벡터 생성\n",
    "sample_hidden = encoder.initialize_hidden_state()   # 클래스 호출해서 히든스테이트 값 만들고\n",
    "\n",
    "# 임의의 테스트 입력과 제로 벡터를 입력\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)   # 64샘플데이터, 제로로채워둔 히든값\n",
    "\n",
    "# (64, 16, 1024)는 각각 (배치 크기, 문장 길이, 은닉 상태의 차원)\n",
    "# (64, 1024)는 각각 (배치 크기, 은닉 상태의 차원)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a44fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바다나우 어텐션 구현\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    print('query_with_time_axis의 shape', query_with_time_axis.shape)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b8694a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "# 바다나우 어텐션 실제 구현 및 리턴한 값 크기 확인\n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape)) # 입력문장 수 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26ab000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바다나우 어텐션을 사용한 디코더 구현\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # 어텐션 사용\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output는 인코더의모든 시점의 은닉 상태\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 임베딩 벡터와 바다나우 어텐션으로 얻은 컨텍스트 벡터를 concat.\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # concat한 결과를 GRU의 입력으로 사용.\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # 현재 시점의 은닉 상태를 리턴\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # 이로부터 현재 시점의 단어 예측\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac02d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 1389)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc4909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8754a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저와 손실 함수 구현\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))  # logical_not : 트루펄스가 바뀌는?\n",
    "  loss_ = loss_object(real, pred)\n",
    "  print(loss_.dtype)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20468e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0067dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output = 모든 시점의 인코더의 hidden state : h1, h2, h3, h4\n",
    "    # 어텐션 메커니즘의 values\n",
    "\n",
    "    # enc_hidden : 마지막 시점의 인코더의 hidden state : h4\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    # 디코더의 첫번째 hidden state로 사용\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # <SOS> 토큰\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 교사 강요 - 현재 시점의 타겟을 다음 시점의 입력으로 사용한다.\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # enc_output는 인코더의 모든 시점의 은닉 상태\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 현재 시점의 타겟을 다음 시점의 입력으로 사용\n",
    "      #tf.print(targ[:, t])\n",
    "      # print(targ[:, t].shape)\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "      #tf.print(dec_input)\n",
    "      # print(dec_input.shape)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  # 미분\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  # 파라미터 업데이트\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfef7344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "query_with_time_axis의 shape (64, 1, 1024)\n",
      "<dtype: 'float32'>\n",
      "Epoch 1 Batch 0 Loss 4.4800\n",
      "Epoch 1 Loss 2.6407\n",
      "Time taken for 1 epoch 9.355271339416504 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.0988\n",
      "Epoch 2 Loss 1.9391\n",
      "Time taken for 1 epoch 2.276848316192627 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7734\n",
      "Epoch 3 Loss 1.6839\n",
      "Time taken for 1 epoch 2.3044846057891846 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.4713\n",
      "Epoch 4 Loss 1.4610\n",
      "Time taken for 1 epoch 2.289914846420288 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.4112\n",
      "Epoch 5 Loss 1.3002\n",
      "Time taken for 1 epoch 2.304457187652588 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.0700\n",
      "Epoch 6 Loss 1.1747\n",
      "Time taken for 1 epoch 2.2840092182159424 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.9738\n",
      "Epoch 7 Loss 1.0646\n",
      "Time taken for 1 epoch 2.3306593894958496 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.9565\n",
      "Epoch 8 Loss 0.9694\n",
      "Time taken for 1 epoch 2.3110389709472656 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8433\n",
      "Epoch 9 Loss 0.8687\n",
      "Time taken for 1 epoch 2.304898977279663 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7498\n",
      "Epoch 10 Loss 0.7829\n",
      "Time taken for 1 epoch 2.2900354862213135 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):   # take : 한번 실행\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0bef551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 단계에서의 동작\n",
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  # 입력된 문장에 대해서 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 토큰화 및 정수 인코딩 및 패딩\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "\n",
    "  # 인코더 수행\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  # 시작 토큰 정의\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  # 테스트 단계\n",
    "  for t in range(max_length_targ):\n",
    "    # 디코더를 동작.\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # 뒤에서 그래프를 그리기 위해서 어텐션 가중치를 저장\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    # 예측으로부터 얻은 정수\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    # 현재 시점에 예측한 단어를 최종 결과로 리턴할 문장에 추가\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    # eos를 만나면 종료\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # 현재 시점의 예측을 다음 시점의 입력으로 사용\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dbb5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 가중치의 시각화\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3610518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d20b5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력된 문장에 대해서 번역 및 시각화\n",
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "083397f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "query_with_time_axis의 shape (1, 1, 1024)\n",
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s a fox . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == \"__main__\":\n",
      "C:\\Users\\bitcamp\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eff03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab21f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de08f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5463d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9521a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523418e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e92e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36229c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5b309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d4d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865f5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf1103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78721b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a269645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961cff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fd4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a9da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d254966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27670e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
